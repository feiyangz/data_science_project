---
title: "data_science_project"
output: html_document
---

```{r}
library(rvest)
library(stringr)
library(dplyr)
library(ggplot2)


#find the website of data scientist positions in the united states from the data jobs

Basic.url <- "https://datajobs.com/Data-Science-Jobs"
url.1 <-paste0("https://datajobs.com/Data-Science-Jobs","~",1:50)
start.page <-read_html(Basic.url) 
#count pages we have (by search for "next page")
res.2 <- sapply(url.1, function(x) {
  desc.2 <- x %>% read_html() %>% html_nodes("div:nth-child(26)") %>% html_text()
NEXT <- any(grepl("\\NEXT\\b", desc.2, ignore.case=TRUE))
})
Page.num <- length(which(res.2==TRUE))+1
url <-paste0("https://datajobs.com/Data-Science-Jobs","~",1:Page.num)


#company
company <- lapply(url,
             function(url){
                    url %>% read_html() %>% 
                        html_nodes("a .stealth-header") %>% 
                        html_text()
 })
company1=unlist(company, recursive = FALSE)

#location
location <- lapply(url,
             function(url){
                    url %>% read_html() %>% 
                        html_nodes("em .stealth-header") %>% 
                        html_text()
 })
location1=unlist(location, recursive = FALSE)

#single job URL for all the pages
page.links <- lapply(url,
              function(url){
                url %>%read_html() %>%
  html_nodes(xpath = '//div[contains(concat( " ", @class, " " ), concat( " ", "stealth-header", " " ))]//a') %>%
  html_attr('href')
  })
page.links1 <- unlist(page.links, recursive = FALSE)
job.urls <-lapply(page.links1, function(x) paste0("https://datajobs.com/", x))
job.urls1 <- unlist(job.urls, recursive = FALSE)

#skills(python,R,SAS,SQL,Java,Tableau,Spark,C++,Perl,Excel)
res <- sapply(job.urls1, function(x) {
  desc <- x %>% read_html() %>% html_nodes("#job_description .jobpost-table-cell-2 , #job_description .jobpost-table-cell-2 strong") %>% html_text()
  Python <- any(grepl("python", desc, ignore.case=TRUE))
  R <- any(grepl("\\bR\\b", desc, ignore.case=TRUE))
  SAS <- any(grepl("\\bSAS\\b", desc, ignore.case=TRUE))
  SQL <- any(grepl("\\bSQL\\b", desc, ignore.case=TRUE))
  Java <- any(grepl("\\bJava\\b", desc, ignore.case=TRUE))
  Tableau <- any(grepl("\\bTableau\\b", desc, ignore.case=TRUE))
  Spark <- any(grepl("\\bSpark\\b", desc, ignore.case=TRUE))
   C<- any(grepl("\\bC\\b", desc, ignore.case=TRUE))
   Perl <- any(grepl("\\bPerl\\b", desc, ignore.case=TRUE))
   Excel <- any(grepl("\\bExcel\\b", desc, ignore.case=TRUE))
 
   # info <- paste0(x %>% read_html() %>% html_nodes(xpath='//*[contains(concat( " ", @class, " " ), concat( " ", "-key", " " ))]') %>% html_text(),
                # x %>% read_html() %>% html_nodes(xpath='//*[contains(concat( " ", #@class, " " ), concat( " ", "-value", " " ))]') %>% html_text())
#  ind <- grep("Industry", info)
 # sector <- ifelse(length(ind) == 0, NA, gsub("Industry: ", "", info[grep("Industry", info)]))
  
c(Python=Python, R=R,SAS=SAS,SQL=SQL,Java=Java,Tableau=Tableau,Spark=Spark,C=C,Perl=Perl,Excel=Excel)
})
res <- unname(res)


data <- data.frame("Company" = company1, "Location"=location1, "Python"=res[1,], "R"=res[2,], "SAS"=res[3,],"SQL"=res[4,],"Java"=res[5,],"Tableau"=res[6,],"Spark"=res[7,],"C"=res[8,],"Perl"=res[9,],"Excel"=res[10,],"Website"=job.urls1)


```















